{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83c\udfe0 Start","text":"<p>\ud83d\udc4b Welcome to my portfolio Hi! I'm Kamil Semczuk, a Computer Science student passionate about building projects that combine data engineering, data analysis, machine learning, and AI-driven applications.</p> <p>In this portfolio, you\u2019ll find selected projects that demonstrate both my technical skills and my problem-solving approach, from raw data to deployed interactive solutions.</p> <p>\ud83d\udd27 Technologies I Work With \ud83d\udc0d Python \u2013 pandas for data manipulation, PyCaret and scikit-learn for machine learning, Streamlit for building interactive data apps</p> <p>\ud83e\udde0 AI &amp; LLMs \u2013 experience with OpenAI APIs, Langfuse for observability, and Instructor for structured outputs from language models</p> <p>\ud83d\uddc4\ufe0f SQL (Intermediate) \u2013 strong command of queries, CTEs, subqueries, window functions (RANK, ROW_NUMBER, PARTITION BY), transactions, CASE WHEN logic, and table design</p> <p>\u26a1 Data Engineering \u2013 building ETL pipelines in Python (pandas), handling file formats (CSV, Excel, JSON), deploying projects on DigitalOcean; currently expanding into PySpark, Apache Kafka, and Kubernetes</p> <p>\ud83c\udf10 Web &amp; Applications \u2013 developing Streamlit apps, deploying to DigitalOcean,working with cloud storage and buckets for loading/dumping data and ML models</p> <p>\u2601\ufe0f Cloud Tools \u2013 using boto3 to interact with AWS S3 for data storage and retrieval, creating Azure SQL Databases, configuring servers, and managing data via Azure </p> <p>\ud83d\udcca Data Visualization \u2013 creating insightful visuals with matplotlib, seaborn, and plotly</p>"},{"location":"Data%20Analysis/Iris/","title":"Data Analysis \u2013 Iris Dataset (EDA)","text":"<p>An exploratory data analysis (EDA) of the famous Iris dataset. This project focuses on understanding the relationships between different features of the flowers. It includes visualizations, insights, and observations that highlight how much valuable information can be extracted from this classic dataset.</p> <p>     \ud83d\udcd8 Check the notebook of Iris analysis </p> <p></p>"},{"location":"Data%20Analysis/Titanic/","title":"Data Analysis \u2013 Titanic (EDA)","text":"<p>An exploratory data analysis of Titanic passengers, aimed at identifying the factors that influenced survival during the disaster. The dataset includes information such as gender, age, travel class, family relationships on board, and port of embarkation. The analysis involved initial data cleaning, visualizations, and comparisons between passenger groups. This project demonstrates how historical data can be used to draw practical insights and build analytical intuition.</p> <p>     \ud83d\udcd8 Check the notebook of Titanic analysis </p> <p></p>"},{"location":"Data%20Engeneering/Shop/","title":"\ud83d\uded2 Shop Data Explorer \u2013 Retail Data Pipeline &amp; Interactive Dashboard","text":"<p>   \ud83d\udea7 The project is in progress. To check the code, click the button below: </p>      \ud83d\udc19 You can check code on GitHub    <p>A project focused on building a complete retail data pipeline, transforming raw CSV files into a fully interactive analytical application. The goal was to create a system capable of automated data ingestion, cleaning, and transformation, followed by visualization through a dashboard designed to support business decision-making.</p> <p>\u2699\ufe0f Key Data Engineering Components: - Designing and executing SQL queries to extract structured insights from a relational database (SQLite) - Building a modular ETL pipeline in Python to clean, transform, and aggregate sales data - Implementing robust data cleaning functions to handle nulls, empty strings, and inconsistent entries - Mapping and standardizing categorical values (e.g. product categories, months) - Structuring data for analytical use (e.g. ranking, grouping, pivoting) - Integrating the pipeline with a Streamlit-based dashboard for interactive exploration</p> <p>\ud83d\udcca App Features: - Filtering data by year, customer, product, and performance type - KPI visualizations: total revenue, top/worst performers, client-level insights - Interactive charts showing monthly trends, product rankings, and category performance</p> <p>\ud83e\uddf0 Tech Stack: - Python (pandas, matplotlib, seaborn) - SQL (SQLite queries with window functions and CTEs) - Streamlit (frontend and app logic) - GitHub Pages (project documentation)</p> <p>This project demonstrates the practical application of Data Engineering in a business analytics context \u2014 turning raw data into a structured, insightful product.</p>"},{"location":"Data%20Science/Loty/","title":"\u2708\ufe0f Flight 4 U \u2013 Intelligent Flight Search App","text":"\ud83c\udf0d \u2708\ufe0f \ud83d\udcf1 Flight 4 U \u2013 Open App         \ud83d\udc19 Check code on GitHub"},{"location":"Data%20Science/Maraton/","title":"\ud83c\udfc3\u200d\u2642\ufe0f Half-Marathon Finish Time Predictor","text":"\ud83d\ude80 Open Notebook \u2013 Cloud Data Ingestion, ML Modeling &amp; Deployment         \ud83d\udc19 Check code on GitHub"}]}